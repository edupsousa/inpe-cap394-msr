{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAP 394-1 - Introdução à Data Science\n",
    "### Eduardo Pereira de Sousa\n",
    "## Tema: Decomposição de Software por meio do Acoplamento Semântico\n",
    "\n",
    "A qualidade de um software pode ser medida por diferentes pontos de vista, dentre esses, a análise de métricas do código-fonte é um dos mais relevantes ao processo de desenvolvimento e manutenção.\n",
    "\n",
    "Essas métricas expressam diferentes características do código-fonte, no caso de softwares orientados à objeto é comum o uso das métricas propostas por _Chidamber e Kemerer_ (CK), como: número de métodos por classe, acoplamento entre classes e coesão entre métodos de uma classe.\n",
    "\n",
    "Essas métricas servem de base para diversas ferramentas e métodos de análise, como os _bad smells_, que são características de classes e métodos que podem indicar a ocorrência de problemas mais graves nesses componentes. Uma classe possui um determinado _bad smell_ caso suas métricas ultrapassem um conjunto pré-definido de limiares.\n",
    "\n",
    "_Aniche et al._ mostrou que esses limiares podem ser mais eficientes na identificação dos _bad smells_ caso se considere o papel do componente na arquitetura do software na definição dos limiares sob os quais cada classe será avaliada.\n",
    "\n",
    "A definição do papel arquitetural de uma determinada classe frente ao software que ela compõe é por si só uma questão em aberto, visto que o método aplicado por _Aniche et al._ baseia-se em características próprias dos _frameworks_ Spring MVC e Android, as quais não podem ser aplicadas de forma geral a outros softwares, ainda que desenvolvidos na mesma linguagem.\n",
    "\n",
    "Nesse ponto, o trabalho de _Bavota et al_ evidencia um possível caminho na decomposição de sistemas de software por meio do acoplamento semântico de seus componentes. Seu trabalho aponta que o acoplamento semântico é aquele capaz de expressar com maior fidelidade a percepção dos próprios desenvolvedores, quando comparado a outros métodos de análise do acoplamento. O acoplamento semântico utiliza a similaridade do vocabulário de classes e métodos como forma de evidenciar as relações entre esses componentes.\n",
    "\n",
    "Neste trabalho, exploraremos diferentes metodologias e técnicas para obtenção, visualização e análise do vocabulário, comparando essas abordagens quanto a capacidade de recuperar a decomposição original da aplicação em pacotes e segundo o método originalmente usado por Aniche et al. na análise de projetos desenvolvidos com o framework Spring MVC. Nosso objetivo é explorar e verificar o comportamento e os resultados obtidos com diferentes abordagens, além de explorar técnicas que permitam a visualização dos dados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project to be retrieved\n",
    "project_org = 'spring-projects'\n",
    "project_name = 'spring-petclinic'\n",
    "# Where to store the repository locally\n",
    "local_path = os.path.join('./repositories', project_org, project_name)\n",
    "# From where to grab the repository\n",
    "github_url = 'https://github.com/{}/{}.git'.format(project_org, project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something wrong is not right...\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "try:\n",
    "    Repo.clone_from(github_url, local_path, depth=1)\n",
    "except:\n",
    "    print('something wrong is not right...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Corpus from Java Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.base import Bunch\n",
    "import javalang\n",
    "import glob\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_grab = [javalang.tokenizer.Identifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corpus(token_list, after_line):\n",
    "    corpus = []\n",
    "    line_words = []\n",
    "    line_number = 0\n",
    "    for token in token_list:\n",
    "        token_line = token.position[0]\n",
    "        if token_line < after_line:\n",
    "            continue\n",
    "        if token_line > line_number:\n",
    "            line_number = token_line\n",
    "            if len(line_words) > 0:\n",
    "                corpus.append(' '.join(line_words))\n",
    "                line_words = []\n",
    "        if type(token) in tokens_to_grab:\n",
    "            line_words.append(token.value)\n",
    "    if len(line_words) > 0:\n",
    "        corpus.append(' '.join(line_words))\n",
    "    return '\\n'.join(corpus)\n",
    "\n",
    "def get_source_code(filename):\n",
    "    f = io.open(filename, 'r', encoding=\"utf-8\")\n",
    "    source_code = f.read()\n",
    "    f.close()\n",
    "    return source_code\n",
    "\n",
    "def in_project_path(project_path, file_path):\n",
    "    return file_path[len(project_path):]\n",
    "\n",
    "def get_project_corpus(project_path):\n",
    "    data = []\n",
    "    path = []\n",
    "    for filename in glob.iglob(project_path + \"/**/*.java\", recursive=True):\n",
    "        source_code = get_source_code(filename)\n",
    "        try:\n",
    "            ast = javalang.parse.parse(source_code)\n",
    "            if len(ast.types) == 0:\n",
    "                break\n",
    "            start_line = ast.types[0].position[0]\n",
    "            token_list = list(javalang.tokenizer.tokenize(source_code))\n",
    "            path.append(in_project_path(project_path, filename))\n",
    "            data.append(extract_corpus(token_list, start_line))\n",
    "        except javalang.parser.JavaSyntaxError as e:\n",
    "            print(\"Syntax error parsing {}\".format(filename))\n",
    "    \n",
    "    return Bunch(data=data,\n",
    "                path=path)\n",
    "\n",
    "corpus = get_project_corpus(local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix of word counts\n",
    "count_vectorizer = CountVectorizer(analyzer='word', min_df = 0)\n",
    "count_matrix = count_vectorizer.fit_transform(corpus.data)\n",
    "# Transform count to frequency (TF/IDF)\n",
    "tf_transformer = TfidfTransformer(use_idf=True)\n",
    "freq_matrix =  tf_transformer.fit_transform(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_similar(tfidf_matrix, index, top_n = 5):\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n",
    "    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]\n",
    "\n",
    "def most_similar(tfidf_matrix, index):\n",
    "    return find_similar(tfidf_matrix, index, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetclinicIntegrationTests.java is 68.17% similar to vet/VetController.java\n",
      "service/EntityUtils.java is 3.22% similar to service/ClinicServiceTests.java\n",
      "service/ClinicServiceTests.java is 34.10% similar to owner/PetController.java\n",
      "owner/PetControllerTests.java is 82.49% similar to owner/OwnerControllerTests.java\n",
      "owner/PetTypeFormatterTests.java is 58.42% similar to owner/PetTypeFormatter.java\n",
      "owner/OwnerControllerTests.java is 82.49% similar to owner/PetControllerTests.java\n",
      "owner/VisitControllerTests.java is 82.39% similar to owner/PetControllerTests.java\n",
      "system/CrashControllerTests.java is 70.14% similar to owner/PetControllerTests.java\n",
      "vet/VetTests.java is 38.30% similar to vet/VetRepository.java\n",
      "vet/VetControllerTests.java is 52.92% similar to system/CrashControllerTests.java\n",
      "model/ValidatorTests.java is 18.74% similar to service/ClinicServiceTests.java\n",
      "PetClinicApplication.java is 4.07% similar to owner/Owner.java\n",
      "owner/OwnerController.java is 51.26% similar to owner/PetController.java\n",
      "owner/PetType.java is 43.01% similar to vet/Specialty.java\n",
      "owner/PetTypeFormatter.java is 58.42% similar to owner/PetTypeFormatterTests.java\n",
      "owner/VisitController.java is 53.81% similar to visit/VisitRepository.java\n",
      "owner/Owner.java is 39.90% similar to owner/PetController.java\n",
      "owner/PetValidator.java is 29.35% similar to owner/PetController.java\n",
      "owner/PetRepository.java is 50.31% similar to owner/OwnerRepository.java\n",
      "owner/PetController.java is 51.26% similar to owner/OwnerController.java\n",
      "owner/OwnerRepository.java is 50.31% similar to owner/PetRepository.java\n",
      "owner/Pet.java is 41.28% similar to owner/VisitController.java\n",
      "visit/Visit.java is 24.28% similar to visit/VisitRepository.java\n",
      "visit/VisitRepository.java is 53.81% similar to owner/VisitController.java\n",
      "system/CrashController.java is 21.42% similar to system/WelcomeController.java\n",
      "system/WelcomeController.java is 21.42% similar to system/CrashController.java\n",
      "system/CacheConfiguration.java is 3.65% similar to owner/VisitController.java\n",
      "vet/VetController.java is 78.12% similar to vet/Vets.java\n",
      "vet/Specialty.java is 43.01% similar to owner/PetType.java\n",
      "vet/Vets.java is 78.12% similar to vet/VetController.java\n",
      "vet/Vet.java is 28.87% similar to vet/Specialty.java\n",
      "vet/VetRepository.java is 38.30% similar to vet/VetTests.java\n"
     ]
    }
   ],
   "source": [
    "for index, path in enumerate(corpus.path):\n",
    "    most_similar_index, score = most_similar(freq_matrix, index)\n",
    "    print('{} is {:.2f}% similar to {}'.format(path[53:], score*100, corpus.path[most_similar_index][53:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
